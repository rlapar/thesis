\chapter{Application documentation and examples}

\label{appendix-running}

This appendix serves as simple documentation to the command line interface. 

\section{General settings}

The application is run via command \texttt{python3 cli.py [OPTIONS] TASK}\footnote{\textit{TASK} can be one of \textit{analyze, classify, generate, scan, train}}. The general options include:

\begin{itemize}

\item \texttt{--help} - Show help message an exit.
\item \texttt{--help-task TASK} - Show help message for specific task
\item \texttt{--settings PATH} - Path to custom yaml settings (if not specified, the default one is used)

\end{itemize}

\section{SCAN}

\noindent
Requires three arguments:

\begin{itemize}

\item \texttt{--scandir PATH} - directory to scan.
\item \texttt{--filter PATH} - path to filter JSON to apply.
\item \texttt{--output-json PATH} - path to the newly created sources JSON file.

\end{itemize}

\section{ANALYZE}

\noindent
Arguments:

\begin{itemize}

\item \texttt{--analyzed-csv PATH} - CSV file to analyze (required).
\item \texttt{--analysis-output PATH} - file to save analysis to. If not specified, then print to stdout.
\item \texttt{--json-format} - boolean flag, if true, then analysis is printed as JSON (used for further automatization).

\end{itemize}

\noindent
All arguments can be setup alternatively in YAML file. Further configuration in YAML include:

\begin{itemize}

\item \texttt{common.batch\_size} - chunk of data read in every iteration.
\item \texttt{common.keys\_per\_feature} - applies to FeatureMaker, should be set to 1 (usually, we analyze CSV files with each line representing only one key).
\item \texttt{fm.key\_length} - 512, 1024 or 2048
\item \texttt{fm.binary\_only} - whether or not the features should be represented by binary vectors only (for analysis should be setup to 0)
\item \texttt{fm.features} - features to analyze

\end{itemize}

\noindent
Supported features include\footnote{Features are described in subsection \label{feature-maker}}:

\begin{itemize}

\item \texttt{['bit', \{'i': x\}]} (where \texttt{x} is bit index)
\item \texttt{['mod', \{'n': x\}]} (where \texttt{x} is divisor)
\item \texttt{'line'} (shortcut for taking every bit) 
\item \texttt{'mod3'} (shortcut for \texttt{['mod', \{ 'n': 3 \}]})
\item \texttt{'mod4'} (shortcut for mod 4)
\item \texttt{['xor', \{'indices': (x, y)\}]} (where \texttt{(x, y)} are bit pairs)

\end{itemize}

\subsection*{Example}

To run help about task:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py analyze --help-task

\end{minted}

\noindent
The example below show the usage of the analyze task. First of all, setup YAML:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{yaml}

common:
  batch_size: 500000
  keys_per_feature: 1
...  
fm:
  key_length: 1024
  binary_only: 0
  features:
  - ['mod', {'n': 3}]
  - ['mod', {'n': 4}]
  - ['mod', {'n': 5}]

\end{minted}

\noindent
Then run command:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

cli.py analyze --analyzed-csv <PATH/TO/CSV> \
--analysis-output <PATH/TO/OUTPUT> \
--json-format

\end{minted}

\noindent
This will run the analyze task and on the \texttt{<PATH/TO/CSV>} file, that have 1 key per line of length 1024 bits in batches of 500000 lines. The analyzed features are moduli of 3, 4 and 5. The output is saved in \texttt{<PATH/TO/OUTPUT>} json file. The output can look like:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{json}

"feature_counter": {
  ...
  "2": {
    "('mod', 5)": {
      "[1]": 16821,
      "[2]": 11206,
      "[3]": 11006,
      "[4]": 10967      
    },
    "('mod', 4)": {
    ...  
  },
  ...
},
"group_counter": {
  ...
  "('mod', 5)": {
    "[1]": {
      "1": 23371,
      "2": 16821,
      ...
    },
    ...
  },
  ...
}  

\end{minted}

\noindent
Feature counter shows the counts for features per each group (\texttt{group.feature.value}). Here we can see, that group 2 has bias towards the remainder 1 when divided by 5. The group counter shows the counts for groups per each feature (\texttt{feature.value.group}). Here we can see, that even though the group 2 has bias towards 1 and group 1 is uniformly distributed modulo 5, there is higher chance of getting group 1 than 2. The result could mean, that the neural network would be biased towards the group 1, if this would be the training data.


\section{GENERATE}

\noindent
Arguments:

\begin{itemize}

\item \texttt{--datapath PATH} - path to the generated dataset.
\item \texttt{--single/--dataset} - boolean flag to generate either single CSV or CSV triplet (by default triplet is generated).
\item \texttt{--shuffle/--no-shuffle} - boolean flag, if set, then the target dataset is shuffled (by default is true).
\item \texttt{--sources-path PATH} - sources JSON file generated by SCAN task.
\item \texttt{--relabel} - boolean flag, if set, then relabels the target sources to have consecutive integer numbers (starting with 1).  Can be useful when any groups are skipped, or some group is missing.

\end{itemize}

\noindent
YAML:

\begin{itemize}

\item \texttt{common.batch\_size} - same as with \textit{ANALYZE}.
\item \texttt{common.keys\_per\_feature} -  specifies how many keys should be put into one line of target CSV.
\item \texttt{common.valid\_ratio} - the percentage of validation data (a number between 0 and 1). Applicable only to \texttt{--dataset} option.
\item \texttt{common.test\_ratio} - the percentage of test data (a number between 0 and 1). Applicable only to \texttt{--dataset} option.
\item \texttt{common.number\_of\_groups} - number of groups of the source dataset.
\item \texttt{generate.keys\_per\_group} - how many keys are taken per each group (the generator automatically scales this number within its sources).
\item \texttt{generate.skipped\_groups} - which groups should not be included in the final dataset (i. e. \texttt{skipped\_groups: ["3", "8"]}).
\item \texttt{generate.skipped\_files} - which sources should not be included in the final dataset.
\item \texttt{generate.train\_keys\_multiplicity} - dictionary, where the key specifies the group and the value specifies the multiplicity ratio for train keys. Applicable only to \texttt{--dataset} option.
\item \texttt{generate.merge\_groups} - lists of merged groups (i.e. \texttt{[6,7,8,9]}  merges groups 6, 7, 8, 9 together).

\end{itemize}

\subsection*{Example}

To run help about task:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py generate --help-task

\end{minted}

\noindent
The example below was used to generate a uniform dataset for 13 groups from our  modified dataset. YAML configuration:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{yaml}

common:
  batch_size: 1000000
  keys_per_feature: 1
  valid_ratio: 0.2
  test_ratio: 0.2
  number_of_groups: 64 # the original dataset has 64 sources
...  
generate:
  keys_per_group: 200000
  skipped_groups: []
  skipped_files: []
  train_keys_multiplicity: # replicate training data in small sources
    1: 2
    2: 2
    5: 4
    17: 2
    18: 3
    21: 5
  merge_groups: # merge sources in the same group
  - [2,3]
  - [6,7,8,9]
  - [11,12,13,14]
  - [16,17,18]
  - [19,20,21]
  - [22,23,24,25,26,27,28,29]
  - [30,31,32,33,34,35,36,37,38,39,40]
  - [41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64]
\end{minted}

\noindent
To generate the new dataset we used the JSON file for 1024 bit sources with command:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

cli.py generate --sources-path sources/grouped_1024.json --dataset \
--datapath <PATH_TO_NEW_DATASET> --shuffle --relabel 

\end{minted}

\section{TRAIN}

\noindent
Arguments:

\begin{itemize}

\item \texttt{--datapath PATH} - same as with \textit{GENERATE}.
\item \texttt{--single/--dataset} - same as with \textit{GENERATE}.
\item \texttt{--incremental/--no-incremental} - boolean flag, with the incremental approach, python generators are used to fetch the data to the model, else the whole data is loaded into the memory (by default incremental).
\item \texttt{--results-to-file/--results-to-stdout} - print the train information to the result directory or stdout (by default directory is chosen).
\item \texttt{--model} - name of the used clWe designed a simple CLI for our application for the user. Can be specified in YAML as well.

\end{itemize}

Models are loaded from the models.json file. Key represents the name of the model passed to CLI. The base class is provided to load model dynamically. Further information is provided, which are necessary for a model interface for the specific library (for keras we specified name and topology). Example from this JSON file was shown in the description of the \textit{TRAIN} task in the subsection \ref{models-json}.

Further configuration is set via YAML file:

\begin{itemize}

\item \texttt{common.batch\_size} - same as with \textit{ANALYZE}.
\item \texttt{common.keys\_per\_feature} - same as with \textit{GENERATE}. Specifies how many keys are present in one line of the CSV.
\item \texttt{common.valid\_ratio} - the percentage of validation data (a number between 0 and 1). Applicable only to \texttt{--single} option.
\item \texttt{common.test\_ratio} - the percentage of test data (a number between 0 and 1). Applicable only to \texttt{--single} option.
\item \texttt{common.number\_of\_groups} - same as with \textit{GENERATE}.
\item \texttt{train.epochs} - number of train epochs (applies to keras models).
\item \texttt{train.model} - name of the used model (CLI argument is prioritized).
\item \texttt{fm.*} - for all the settings for feature maker  apply the same description as with ANALYZE, but \texttt{fm.binary\_only} should be in this case 1 instead of 0 (binary vectors for modulo features are better for classifiers).

\end{itemize}

\subsection*{Example}

To run help about task:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py train --help-task

\end{minted}

\noindent
The following example shows configuration from our train runs. YAML:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{yaml}

common:
  batch_size: 2048
  keys_per_feature: 1
  valid_ratio: 0.2
  test_ratio: 0.2
  number_of_groups: 13 # newly generated 13 sources
...  
train:
  epochs: 4
fm:
  key_length: 1024
  binary_only: 1
  features:
  - 'line'
  - 'mod3'
  - 'mod4'
  - ['mod', {'n': 5}]
  - ...
\end{minted}

\noindent
Command:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py train --dataset --incremental \
--datapath <PATH_TO_NEW_DATASET> \
--model Keras28

\end{minted}

\noindent
Model topology configuration:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{json}

"Keras28": {"base": "KerasDeepClassifier",
             "name": "Keras ReLU Deep NN",
             "topology": {"hidden_layers": [{"activation": "relu",
                                             "number_of_neurons": 128},
                                            {"activation": "relu",
                                             "number_of_neurons": 1024}],
                          "loss": "categorical_crossentropy",
                          "metrics": ["acc"],
                          "optimizer": "Adadelta",
                          "output_layer": {"activation": "softmax"}}},

\end{minted}

The results are saved in \texttt{results} directory with incrementing \texttt{run\_id}. Each run stores \texttt{classifier}, \texttt{config.txt} (configuration from YAML), \texttt{run\_info.txt} (information about dataset, features, model and time of run) and \texttt{results.txt} (evaluation - confusion matrix and accuracy table).

\section{CLASSIFY}

\noindent
Arguments:

\begin{itemize}

\item \texttt{--classifier PATH} - path to the model trained by \textit{TRAIN} task
\item \texttt{--source-csv PATH} - source CSV to classify
\item \texttt{--compare-labels/--assign-labels} - boolean flag. If labels are compared, then the modeIf assign labels option is chosen, then the model adds labels to the entries in CSV and store them into the new CSV file.l is evaluated to the given dataset (the same process as with evaluation in \textit{TRAIN} task). If assign labels option is chosen, then the model adds labels to the entries in CSV and store them into the new CSV file.
\item \texttt{--target-csv PATH} - applicable when \texttt{--assign-labels} is set. Path to the target labeled CSV file.

\end{itemize}

\noindent
YAML:

\begin{itemize}

\item \texttt{common.*} - the same as with \textit{TRAIN} (for \textit{CLASSIFY} only options \texttt{common.batch\_size}, \texttt{common.keys\_per\_feature} and \texttt{common.number\_of\_groups} are relevant).

\end{itemize}

\subsection*{Example}

To run help about task:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py classify --help-task

\end{minted}

\noindent
The YAML configuration is similar to train task (fileds \textit{common} and \texttt{fm}). To run the classifier on custom dataset and evaluate its performance:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py classify --classifier <PATH_TO_CLASSIFIER> \
--source-csv <PATH_TO_CSV> --compare-labels

\end{minted}

\noindent
To run the classifier on custom dataset and assign new labels, one does need to provide the path to the newly labeled dataset:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

python3 cli.py classify --classifier <PATH_TO_CLASSIFIER> \
--source-csv <PATH_TO_CSV> --assign-labels \
--target-csv <PATH_TO_LABELED_CSV>

\end{minted}

\section{Running in docker environment}
\label{appendix-docker}

When not on a Debian machine, one can run the application in the docker environment. The user has to bind the used volumes for dataset, results and generated data. User then builds the container and runs it interactivelly by the following commands:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

docker build . -t rsaml --file Dockerfile

docker run -v <path_to_dataset>:/opt/dataset \
-v <path_to_results>:/opt/rsa-ml/results \
-v <path_to_generated_datasets>:/opt/rsa-ml/datasets \
-i -t rsaml:latest /bin/bash

\end{minted}

\section{Running on metacentrum}
\label{appendix-metacentrum}

To run the application on Metacenturm we run the shell script, that:

\begin{itemize}

\item specified desired resources (number of processors, memory, scratch memory and maximum runtime)

\item loaded the necessary dependencies

\item installed third party modules locally (in our case \texttt{click})

\item ran the application

\end{itemize}

\noindent
The example of used script is showed below:

\begin{minted}[ framesep=2mm,
                autogobble,
                frame=lines]{shell}

#PBS -l select=1:ncpus=1:mem=8gb:scratch_local=4gb
#PBS -l walltime=3:00:00

# sets home directory
DATADIR="/storage/brno6/home/xlapar"

cd $DATADIR/git/rsa-ml/

module add tensorflow-1.5.0-cpu-python3
module add python34-modules-gcc

# install click
export PYTHONUSERBASE=$DATADIR/.local
export PATH=$PYTHONUSERBASE/bin:$PATH
export PYTHONPATH=$PYTHONUSERBASE/lib/python3.4/site-packages:$PYTHONPATH
pip install click --user --process-dependency-links

# export for click
export LC_ALL=C.UTF-8
export LANG=C.UTF-8

python3 $DATADIR/git/rsa-ml/cli.py train \
--dataset --incremental \
--datapath $DATADIR/data/datasets/dataset_1 \
--settings $DATADIR/settings/generate/groups_13/1024.yaml \
--model $MODEL

\end{minted}









