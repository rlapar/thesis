\chapter{Conclusion}

In this thesis, we studied the use of neural networks in the classification process of public keys in RSA implementations. The work served as an extension of already ongoing research of CROCS lab in this field. 

We performed a detailed distributed analysis of given dataset and found out different distributions on the six most significant bits which we presented in figure \ref{figure-table-bit-analysis}. Furthermore, our modular analysis (figure \ref{figure-mod-analysis}) supported the results presented by CROCS team.

A big part of this thesis was the design of an application, capable of working with the given dataset. As there is an assumption, that this application will be further used in CROCS research to try out new classification techniques, we focused on extensibility and efficiency. We implemented an interface that simplifies the training process as it isolates the data fetching to the model as a different logic. The models are accessible via the common interface, which makes the new model integrations easier.

Using our framework, we methodologically compared the traditional methods and neural networks when classifying public keys. Our results showed the limitations in using traditional classifiers, especially with bigger datasets.

The first neural network we trained and optimized using a grid search technique. The task was too complex for the local machine. Thus it had to be trained on CESNET cloud. Our observations showed that the usage of activation or optimizer has a little impact on the overall performance of the model. On the other hand, the uniform training dataset and topology were much more important. This optimized classifier performed better than Naive Bayes, especially on the large classes, where we had sufficient amount of data.

\textbf{TODO second model rewrite}

For the second model, we tried a different approach. Training individual binary classifiers and merging them in the voting process turned out to be the best choice. We trained them individually, optimizing every model by itself by customizing the dataset and hyperparameters. This classifier was able to recognize a couple of groups better, namely groups 1, 4, 5, 8, 9, 12 and 13. Group 8 (PGP DSK 4 with FIPS module) and 9 (Infineon JTOP 80k and Yubikey) are recognizable with high probability using just one key. Large groups 12 and 13 are recognized about 10 \% more likely. Overall the classifier performed with 5 \% better accuracy on the uniform dataset than the existing Naive Bayes classifier.

As the last step, we tried to split the grouping even more precise. However, using the existing features, the neural network is unable to do that. 

For the future work to improve these results, one can try different types of analysis like xor of all pairwise bits on one key. This process would need to be optimized though, as there are $\mathcal{O}(n^2)$ combinations for just one key only. The working voting classifier can be further optimized by training more accurate binary classifiers within the model on larger datasets. Also, one could experiment by adding a hidden layer on top. Other new models can also be included in the application.
