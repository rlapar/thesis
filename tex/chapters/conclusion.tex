\chapter{Conclusion}

In this thesis, we studied the use of neural networks in the classification process of public keys in RSA implementations. The work served as an extension of already ongoing research of CROCS lab in this field. 

We performed a detailed distributed analysis of the given dataset and found out different distributions on the six most significant bits which we presented in \autoref{figure-table-bit-analysis}. Furthermore, our modular analysis (\autoref{figure-mod-analysis}) supported the results presented by CROCS team.

A significant part of this thesis was the design of an application, capable of working with the given dataset. As there is an assumption that this application will be further used in CROCS research to try out new classification techniques, we focused on extensibility and efficiency. We implemented an interface that simplifies the training process as it isolates the data fetching to the model as a different logic. The models are accessible via the common interface, which makes new model integrations easier.

Using our framework, we methodologically compared the traditional methods and neural networks when classifying public keys. Our results showed the limitations in using traditional classifiers, especially with bigger datasets.

The first neural network was trained and optimized using a grid search technique. The task was too complex for the local machine. Thus it had to be trained on CESNET cloud. Our observations showed the optimal activation, topology, and optimizer for this classification problem. The uniform training dataset improved the training process and the overall accuracy on the test set. This optimized classifier performed better than Naive Bayes, especially on the large classes, where we had sufficient amount of data.

For the second model, we tried a different approach. Training individual binary classifiers and merging them in the voting process
turned out to be the best choice for groups with a sufficient amount of data. We could train the binary classifiers individually, optimizing every model by itself by customizing the train dataset and hyperparameters. The voting classifier was able to recognize large groups better compared to Naive Bayes. In practice, the voting model can recognize OpenSSL (group 7) keys\footnote{which make a majority key source in wide TLS scans} with 15 \% more precision than Naive Bayes. Furthermore, recently flawed Infineon chips (group 9) are detected with certainty over 99 \% just from one key, which is 40 \% better than previous results. Other popular libraries like Libgcrypt, OpenSSL FIPS, mbedTLS, etc. (from groups 12 and 13) are recognized with 10 \% more precision than Naive Bayes. 

As the last step, we tried to split the grouping even more precisely. However, using the existing features, the neural network is unable to do that. For the future work to improve these results, one can try different types of analysis like xor of all pairwise bits on one key. This process would need to be optimized though, as there are $\mathcal{O}(n^2)$ combinations for just one key only. The working voting classifier can be further optimized by training more accurate binary classifiers within the model on larger datasets. Also, one could experiment by adding a hidden layer on top. Other new models can also be included in the application.
