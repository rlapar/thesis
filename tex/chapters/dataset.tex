\chapter{Dataset}
\label{chapter-dataset}

For this thesis, we were provided with the dataset consisting of more than 30 sources collected from different software libraries, hardware authentication devices (or cards) and HSM's\footnote{Hardware security modules}. 
Some of the software libraries had the option of so-called FIPS module, which is a security standard, that put some requirements on generated primes and their distribution, namely available in \textit{PGP SDK 4}, \textit{Libgcrypt} and \textit{OpenSSL}. Furthermore, every source had one or more development versions. 

Considering both of these options, we split our dataset into 64 distinct sources based on their version and whether or not they had the FIPS module activated when generating primes. Every source was represented by a couple of CSV files, with fields $n, e, d, p, q$ and $t$ (time of generation). Three key lengths were present (512b, 1024b and 2048b), with most of the data originated from 512b or 1024b.

All in all, a total of more than 146 million keys were collected with roughly 75.5 million of 512b and 65.4 million of 1024b keys. These two datasets were used for machine learning and preparing classification models. A complete overview of the dataset can be seen in Appendix \ref{appendix-dataset}.

In the article by CROCS lab\cite{svenda_1}, different sources were merged into 13 disjoint groups using clustering on the mask of 9 selected bits. Using the naive Bayes classifier, they were able to classify a random sample of keys with the accuracy of 40.34 \%. Therefore, in this thesis, we tried to pick up on these results and further extend the accuracy by using other classifiers while focusing specifically on neural networks.

\section{Dataset analysis}

\label{chapter-analysis}

Before attempting to create a working classifier, the analysis of the dataset and subsequent feature engineering was necessary. We scanned the whole dataset, extracting features from public product $n$. We focused mainly on the bit value on every position and the remainder when divided by a specific number. With every feature, we counted the relative frequency of every possible value. Because of the huge number of keys, we needed to run this analysis distributively on Metacentrum\footnote{distributed cloud computing over CESTNET}.

\subsection{Modular analysis}

As in the full CROCS report\cite{svenda_full}, we did a similar analysis on the full dataset. With every key, we computed a modulo over first 30 natural numbers, starting with 3, while focusing mainly on prime numbers. We were looking for any irregularities in distribution of the remainders. Specifically, with prime numbers $p$, the remainder should be uniformly distributed between 1 and $p-1$. Several sources showed bias, namely:

\begin{itemize}

\item \textit{mod 3} - sources 2,3 (G\&D SmartCafe 4.x and 6.0), 11-14 (OpenSSL without FIPS module) and 19, 20, 21 (NXP J2D081, NXP J2E145G, YubiKey NEO) were always giving a remainder of 1.

\item \textit{mod 4} - sources 1, 2, 3 (G\&D SmartCafe) 4 (GNU Crypto 2.0.1) 6, 7, 8, 9 (NXP J2A*, NXPJ3A*, NXP JCOP 41 V2.2.1), 10 (Oberthur Cosmo Dual 72K) and 19, 20, 21 were always giving a remainder of 1. Sources that were giving a remainder of 1 modulo 3 and 4 are using Blum integers.

\item \textit{module 11} - sources 16, 17, 18 (Infineon, Yubikey and Yubikey Nano) were giving only remainders of 1 or 10. Sources 11, 12, 13, 14, 19, 20 had slight bias towards the remainder of 1.

\end{itemize}

\noindent
Full results of modular analysis can be seen in Appendix \ref{appendix-modular-analysis}.

\subsection{Bit analysis}

Another analysis focused on full bit analysis. Similarly, as in the previous one, we computed the relative frequency (or probability of 0) on every bit position with each source. This kind of analysis took a more significant amount of time and needed to be computed distributively. It took a couple of hours compared to the estimated time of up to one week when computing on the local machine. The analysis showed a significant bias in the first 6 most significant bits, mostly:

\begin{itemize}

\item \textbf{1st MSB} was always 1 (for bit length padding) with one exception of source 15 (PGP SDK FIPS 4), which contained a majority of its keys with shorter bit length.

\item \textbf{2nd - 4th MSB} could distinguish a lot of groups (i.e. 16-18 or 1-3), because of wider probability distribution.

\item \textbf{5th - 6th MSB} still had slight bias in probability distribution for some groups (4, 19-21, 31-40)

\item \textbf{2nd LSB} could distinguish mostly groups that were using Blum primes (1-4, 6-10, 19-21)

\end{itemize}

\noindent
Full results of bit analysis can be seen in Appendix \ref{appendix-bit-analysis}.

\subsection{Feature engineering}

\label{feature-engineering}

Based on the previous analysis we extracted the following features from the public key to feed to the network:

\begin{itemize}

\item all moduli remainders up to 30 represented as binary vector\footnote{For example for $x \equiv 1 \pmod{5}$, the feature vector is $(1,0,0,0)$, $x \equiv 2 \pmod{5}$ - $(0,1,0,0)$, $\cdots$}

\item The key itself

\end{itemize}

\noindent
The performance of the network was similar regardless of using the full key, or just the biased bits.

\subsection{Source grouping}
If we look closely on the full analysis in Appendix \ref{appendix-analysis}, we can see that based on the feature engineering we can natively group sources, that share the distribution. We obtain 13 groups\footnote{Same grouping was obtained by cluster analysis in \cite{svenda_1}}:

\vspace{5mm}

\noindent
\begin{tabular}{|r|l||r|l||r|l|}

\hline

\textbf{G1} & 1 & \textbf{G6} & 10 & \textbf{G10} & 19, 20, 21 \\
\textbf{G2} & 2, 3 & \textbf{G7} & 11, 12, 13, 14 & \textbf{G11} & 22 - 29 \\
\textbf{G3} & 4 & \textbf{G8} & 15 & \textbf{G12} & 30 - 40 \\
\textbf{G4} & 5 & \textbf{G9} & 16, 17, 18 & \textbf{G13} & 41 - 64 \\
\textbf{G5} & 6, 7, 8, 9 & & & & \\

\hline

\end{tabular}
